{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "\n",
    "bookings_df = spark.table(\"bookings\")\n",
    "facilities_df = spark.table(\"facilities\")\n",
    "\n",
    "#another way of doing it without tables.\n",
    "# bookings_df = spark.read.csv(\"/FileStore/tables/bookings.csv\", header=True, inferSchema=True)\n",
    "# members_df = spark.read.csv(\"/FileStore/tables/members.csv\", header=True, inferSchema=True)\n",
    "\n",
    "result_df = (\n",
    "    members_df\n",
    "    .join(bookings_df, members_df.memid == bookings_df.memid)\n",
    "    .filter((members_df.firstname == 'David') & (members_df.surname == 'Farrell'))\n",
    "    .select(bookings_df.starttime)\n",
    ")\n",
    "\n",
    "result_df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the bookings and facilities tables into DataFrames\n",
    "bookings_df = spark.table(\"bookings\")\n",
    "facilities_df = spark.table(\"facilities\")\n",
    "\n",
    "# Perform the join and filter operations\n",
    "result_df = (\n",
    "    bookings_df\n",
    "    .join(facilities_df, bookings_df.facid == facilities_df.facid)\n",
    "    .filter((col(\"starttime\").cast(\"date\") == '2012-09-21') & (col(\"name\").like(\"%Tennis%\")))\n",
    "    .select(\"starttime\", \"name\")\n",
    "    .orderBy(\"starttime\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the members table into a DataFrame\n",
    "members_df = spark.table(\"members\")\n",
    "\n",
    "# Self-join to include the recommended by information\n",
    "result_df = (\n",
    "    members_df.alias(\"m1\")\n",
    "    .join(members_df.alias(\"m2\"), col(\"m1.recommendedby\") == col(\"m2.memid\"), \"left_outer\")\n",
    "    .select(\n",
    "        col(\"m1.memid\"),\n",
    "        col(\"m1.surname\").alias(\"member_surname\"),\n",
    "        col(\"m1.firstname\").alias(\"member_firstname\"),\n",
    "        col(\"m1.recommendedby\"),\n",
    "        col(\"m2.surname\").alias(\"recommendedby_surname\"),\n",
    "        col(\"m2.firstname\").alias(\"recommendedby_firstname\")\n",
    "    )\n",
    "    .orderBy(\"member_surname\", \"member_firstname\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat_ws\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the bookings, facilities, and members tables into DataFrames\n",
    "bookings_df = spark.table(\"bookings\")\n",
    "facilities_df = spark.table(\"facilities\")\n",
    "members_df = spark.table(\"members\")\n",
    "\n",
    "# Perform the joins and filter operations\n",
    "result_df = (\n",
    "    bookings_df\n",
    "    .join(facilities_df, bookings_df.facid == facilities_df.facid)\n",
    "    .join(members_df, bookings_df.memid == members_df.memid)\n",
    "    .filter(col(\"name\").like(\"%Tennis%\"))\n",
    "    .select(\n",
    "        concat_ws(' ', col(\"firstname\"), col(\"surname\")).alias(\"member_name\"),\n",
    "        col(\"name\").alias(\"facility_name\")\n",
    "    )\n",
    "    .distinct()  # Ensure no duplicate data\n",
    "    .orderBy(\"member_name\", \"facility_name\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# having some issue here. q5\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat_ws, when\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the members table into a DataFrame\n",
    "members_df = spark.table(\"members\")\n",
    "\n",
    "# Self-join to include the recommended by information\n",
    "result_df = (\n",
    "    members_df.alias(\"m1\")\n",
    "    .join(members_df.alias(\"m2\"), col(\"m1.recommendedby\") == col(\"m2.memid\"), \"left_outer\")\n",
    "    .select(\n",
    "        col(\"m1.memid\"),\n",
    "        col(\"m1.firstname\").alias(\"member_firstname\"),\n",
    "        col(\"m1.surname\").alias(\"member_surname\"),\n",
    "        col(\"m1.recommendedby\"),\n",
    "        col(\"m2.firstname\").alias(\"recommendedby_firstname\"),\n",
    "        col(\"m2.surname\").alias(\"recommendedby_surname\")\n",
    "    )\n",
    "    .distinct()  # Ensure no duplicate data\n",
    "    .orderBy(\"member_firstname\", \"member_surname\")\n",
    ")\n",
    "\n",
    "# Concatenate member and recommended by names into a single column\n",
    "result_df = result_df.withColumn(\n",
    "    \"member_and_recommendedby\",\n",
    "    when(col(\"recommendedby\").isNotNull(),\n",
    "         concat_ws(' ', col(\"recommendedby_firstname\"), col(\"recommendedby_surname\"))\n",
    "        )\n",
    "        .otherwise(concat_ws(' ', col(\"member_firstname\"), col(\"member_surname\")))\n",
    ")\n",
    "\n",
    "# Select relevant columns for the final output\n",
    "result_df = result_df.select(\"member_and_recommendedby\")\n",
    "\n",
    "# Show the result\n",
    "result_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the members table into a DataFrame\n",
    "members_df = spark.table(\"members\")\n",
    "\n",
    "# Group by recommendedby and count the number of recommendations\n",
    "recommendations_count_df = (\n",
    "    members_df\n",
    "    .groupBy(\"recommendedby\")\n",
    "    .agg(count(\"*\").alias(\"recommendations_count\"))\n",
    "    .orderBy(\"recommendedby\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "recommendations_count_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the bookings table into a DataFrame\n",
    "bookings_df = spark.table(\"bookings\")\n",
    "\n",
    "# Group by facility id and sum the number of slots booked\n",
    "facility_slots_df = (\n",
    "    bookings_df\n",
    "    .groupBy(\"facid\")\n",
    "    .agg(sum(\"slots\").alias(\"total_slots\"))\n",
    "    .orderBy(\"facid\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "facility_slots_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, col, month, year\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the bookings table into a DataFrame\n",
    "bookings_df = spark.table(\"bookings\")\n",
    "\n",
    "# Filter bookings for the month of September 2012\n",
    "september_bookings_df = bookings_df.filter((month(\"starttime\") == 9) & (year(\"starttime\") == 2012))\n",
    "\n",
    "# Group by facility id and sum the number of slots booked\n",
    "facility_slots_df = (\n",
    "    september_bookings_df\n",
    "    .groupBy(\"facid\")\n",
    "    .agg(sum(\"slots\").alias(\"total_slots\"))\n",
    "    .orderBy(col(\"total_slots\").desc())\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "facility_slots_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, col, month, year\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the bookings table into a DataFrame\n",
    "bookings_df = spark.table(\"bookings\")\n",
    "\n",
    "# Filter bookings for the year 2012\n",
    "year_2012_bookings_df = bookings_df.filter(year(\"starttime\") == 2012)\n",
    "\n",
    "# Group by facility id and month, then sum the number of slots booked\n",
    "facility_slots_per_month_df = (\n",
    "    year_2012_bookings_df\n",
    "    .groupBy(\"facid\", month(\"starttime\").alias(\"month\"))\n",
    "    .agg(sum(\"slots\").alias(\"total_slots\"))\n",
    "    .orderBy(\"facid\", \"month\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "facility_slots_per_month_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the bookings table into a DataFrame\n",
    "bookings_df = spark.table(\"bookings\")\n",
    "\n",
    "# Count the distinct memids (members and guests) who made at least one booking\n",
    "total_members_with_bookings = bookings_df.select(countDistinct(\"memid\").alias(\"total_members\"))\n",
    "\n",
    "# Show the result\n",
    "total_members_with_bookings.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, min\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the members and bookings tables into DataFrames\n",
    "members_df = spark.table(\"members\")\n",
    "bookings_df = spark.table(\"bookings\")\n",
    "\n",
    "# Filter bookings after September 1st, 2012, and find the minimum booking time for each member\n",
    "min_booking_time_df = (\n",
    "    bookings_df\n",
    "    .filter(col(\"starttime\") > \"2012-09-01\")\n",
    "    .groupBy(\"memid\")\n",
    "    .agg(min(\"starttime\").alias(\"first_booking_after_sep1\"))\n",
    ")\n",
    "\n",
    "# Join with members table to get member details\n",
    "result_df = (\n",
    "    members_df\n",
    "    .join(min_booking_time_df, \"memid\", \"left_outer\")\n",
    "    .select(\n",
    "        \"memid\",\n",
    "        col(\"firstname\").alias(\"member_firstname\"),\n",
    "        col(\"surname\").alias(\"member_lastname\"),\n",
    "        \"first_booking_after_sep1\"\n",
    "    )\n",
    "    .orderBy(\"memid\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result_df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat_ws, col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the members table into a DataFrame\n",
    "members_df = spark.table(\"members\")\n",
    "\n",
    "# Select and format the names\n",
    "result_df = (\n",
    "    members_df\n",
    "    .select(\n",
    "        concat_ws(', ', col(\"surname\"), col(\"firstname\")).alias(\"formatted_name\")\n",
    "    )\n",
    "    .orderBy(\"formatted_name\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the facilities table into a DataFrame\n",
    "facilities_df = spark.table(\"facilities\")\n",
    "\n",
    "# Perform a case-insensitive search\n",
    "result_df = (\n",
    "    facilities_df\n",
    "    .filter(col(\"name\").ilike(\"tennis%\"))\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the members table into a DataFrame\n",
    "members_df = spark.table(\"members\")\n",
    "\n",
    "# Find telephone numbers with parentheses\n",
    "result_df = (\n",
    "    members_df\n",
    "    .filter(col(\"telephone\").contains(\"(\") | col(\"telephone\").contains(\")\"))\n",
    "    .select(\"memid\", \"telephone\")\n",
    "    .orderBy(\"memid\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import substring, count, col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Read the members table into a DataFrame\n",
    "members_df = spark.table(\"members\")\n",
    "\n",
    "# Extract the first letter of each surname\n",
    "members_df = members_df.withColumn(\"surname_first_letter\", substring(\"surname\", 1, 1))\n",
    "\n",
    "# Group by the first letter of the surname and count the occurrences\n",
    "result_df = (\n",
    "    members_df\n",
    "    .groupBy(\"surname_first_letter\")\n",
    "    .agg(count(\"*\").alias(\"count\"))\n",
    "    .orderBy(\"surname_first_letter\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Create a DataFrame with a single column containing all the dates in October 2012\n",
    "dates_df = spark.range(\"2012-10-01\", \"2012-10-31\", 1).select(col(\"id\").cast(\"timestamp\").alias(\"date\"))\n",
    "\n",
    "# Show the result\n",
    "dates_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import year, month\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ETLExample\").getOrCreate()\n",
    "\n",
    "# Assuming you have a DataFrame named bookings_df with a timestamp column named 'starttime'\n",
    "# Replace 'bookings_df' with your actual DataFrame name and adjust the column names accordingly\n",
    "\n",
    "# Extract year and month from the 'starttime' column\n",
    "bookings_df = bookings_df.withColumn(\"year\", year(\"starttime\")).withColumn(\"month\", month(\"starttime\"))\n",
    "\n",
    "# Group by year and month, and count the number of bookings\n",
    "monthly_bookings_count = bookings_df.groupBy(\"year\", \"month\").count().sort(\"year\", \"month\")\n",
    "\n",
    "# Show the result\n",
    "monthly_bookings_count.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1 - Spark Dataframe Data Manipulation (pgexercises)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
